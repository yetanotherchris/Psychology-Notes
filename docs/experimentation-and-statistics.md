# Experimentations Glossary


| Concept                    | Definition                                                                                                                                                                       |
|:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Alternative hypothesis     | What will happen according to the hypothesis, the opposite of the null hypothesis. e.g. 'Students who sleep more perform better on tests.'                                       |
| Averages                   | Central values of data. e.g. mean, median, mode - measures of central tendency                                                                                                   |
| Between participants       | Dividing participants into groups for each condition of the experiment. e.g. Group A receives a drug, Group B receives a placebo.                                                |
| Bimodal                    | If there are two modes, and they're clearly higher (peeks) than other values. Unimodal (1 mode) and multimodal (multiple modes)                                                  |
| Categorical & ranking data | Non-numeric data grouped by category or order. e.g. blood type (categorical), race position (ranking).                                                                           |
| Confounding variables      | Uncontrolled variables that affect the outcome. e.g. diet affecting weight loss in an exercise study.                                                                            |
| Correlational co-efficient | Strength and direction of variable relationship. e.g. Pearson's r = 0.85 indicates strong positive correlation.  week13                                                          |
| Dependent variable         | The measured outcome, e.g. heart rate change                                                                                                                                     |
| Descriptive statistics     | Descriptions of the data from the sample. e.g. a graph or table of data, mean or median.                                                                                         |
| Distribution               | How data values are spread. e.g. normal, skewed, or bimodal.                                                                                                                     |
| Experimental design        | A research design involving manipulation of an independent variable. e.g. testing whether caffeine improves memory by assigning participants to caffeine or no caffeine groups.  |
| Falsification              | Concept that a hypothesis must be disprovable. e.g. 'All swans are white' can be falsified by finding one black swan.                                                            |
| Frequency distribution     | Counts of values in intervals. e.g. histogram of age groups.                                                                                                                     |
| Generalizing               | Generalising from the sample to the population                                                                                                                                   |
| Global Samples             | Diverse samples from various locations. e.g. participants from multiple countries.                                                                                               |
| Graph types                | Scatter plot, histogram, bar chart.                                                                                                                                              |   
| Hypothesis testing         | Statistical procedure to determine support for a hypothesis. e.g. testing if a new drug reduces symptoms more than a placebo.                                                    |
| Hypothesis: one tailed     | A hypothesis that predicts the direction of the two variables, e.g. extra cheese leads to worst sleep                                                                            |
| Hypothesis: two tailed     | A hypothesis that is neutral about the direction or relationship of the two variables                                                                                            |
| Independent Variable       | The manipulated variable. e.g. film category watched                                                                                                                             |
| Inferential statistics     | Statistical tools that allow researchers to their sample to the population.                                                                                                      |
| Line of best fit           | Line approximating data trend in a scatterplot. e.g. average trend in exam scores vs. study time.                                                                                |
| Mean                       | Sum of values divided by number. e.g. average test score.                                                                                                                        |
| Median                     | Middle value in an ordered dataset. e.g. the 5th value in a list of 9 scores.                                                                                                    |
| Measures of central tendency| Mode, median, mean                                                                                                                                                              |
| Mode                       | The most common result, e.g. scores 1,3, 5, 6, 6, 7 it would be 6. There would be no mode if they're all unique.                                                                 |
| NHST                       | TODO                                                                                                                                                                             |
| Normal distribution        | The mean, median, and mode are equal. The data is symmetric (bell curve). The data tapers off gradually. AKA Gaussian distribution                                               |                                                                                           |
| P-Value                    | Probability between 0 and 1                                                                                                                                                      |
| Qualitative data           | Descriptive data. e.g. interviews.                                                                                                                                               |
| Quantitative data          | Numerical data. e.g. height, temperature.                                                                                                                                        |
| Quasi experimental         | An experimental design without random assignment. e.g. comparing student performance across two existing classes.                                                                |
| Range                      | Difference between highest and lowest values. e.g. if scores range from 60 to 90, the range is 30.                                                                               |
| Sample                     | Selecting a subset of a population. e.g. choosing 100 students from a university.                                                                                                |
| Sampling variation         | Each time you choose 10 subjects for your sample, you might get variation in the mean of the value you want to measure, e.g. height. It might also be different from the population. Sample size is important, and inferential statistics are used to generalise to the population. |
| Sampling error             | Error from using a sample instead of the full population. e.g. survey results differ from actual population values.                                                              |
| Sampling error: Type 1     | Rejecting a true null hypothesis. e.g. concluding a drug works when it doesn't.                                                                                                  |
| Sampling error: Type 2     | Failing to reject a false null hypothesis. e.g. missing the effect of a useful drug.                                                                                             |
| Scale                      | Measurement system classifying data. e.g. nominal, ordinal, interval, ratio scales.                                                                                              |
| Scatterplot                | Graph showing a two variable relationship. e.g. height vs. weight.                                                                                                               |
| Standard deviation         | Spread of data around the mean. e.g. SD = 2 means most scores lie within 2 points of the mean.                                                                                   |
| Statistical significance   | In psychology, statistical significance occurs when the p-value, calculated from a test like chi-squared, is less than 0.05 (5%). This means there's less than a 5% chance the results are due to random variation if the null hypothesis is true, so we reject it for the alternative hypothesis. |
| Within participants        | The same group of people are affected by different conditions of the independent variable, e.g. juror's guilty verdict before and after deliberation                             |

## Value types
| Concept                    | Definition                                                                                                                                                                       |
|:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Nominal                    | Categories with no order (e.g., types of fruit, colours).|
| Ordinal                    | Data with a clear order, the interval between each value isn't always equal (e.g., rankings, scariest horror films, GCSE, A Level, BSc, Ph.D.).                                  |
| Interval                   | Ordered items with equal spacing, and no true zero (e.g., temperature in Celsius, IQ, dates in a calendar).|
| Ratio                      | Ordered, equal spacing, and has a true zero (e.g. height, money, weight, age). You can form ratios from the data e g 50kg is double 25kg.|


## Statistical test types / designs
| Concept                    | Definition                                                                                                                                                                       |
|:---------------------------|:---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| Chi-squared                | Test for relationship between categorical variables. e.g. testing if gender is related to voting preference.                                                                     |
| Correlational              | A type of research design that examines the relationship between variables without manipulation. e.g. measuring the relationship between hours studied and exam scores.          |
| Independent t-test         | |
| Paired samples t-test      | |
|Pearson correlation test|when the data are interval or ratio|

## Sampling Error

The group in the study is the sample. The wider group is the population, which depends on the research question.
The sample is generalised to the population.

Sampling error is the natural variability between a sample estimate and the true population value.

Let‚Äôs say the true average IQ in a country is 100.

- A small sample of 10 people might give you an average of 105 or 95 ‚Äî lots of variation.
- A large sample of 1,000 people might give you 99.8 or 100.2 ‚Äî closer to the true value.
- Both have sampling error, but the larger sample has less.

### Formula
Standard¬†Error¬†(SE) = s / sqrt(n)
‚Äã 
Where:
ùë† = sample standard deviation
ùëõ = sample size

### Reducing error
Reducing sampling error:
- Larger sample size
- Random sampling to reduce bias
- Stratified sampling (key groups being represented)


### Pearson's R values

You can be negative values, so -1 is a perfect negative linear relationship.

| **r value** | **Interpretation / Strength** |
| ----------- | ----------------------------- |
| 0.00 ‚Äì 0.10 | **Negligible / Very weak**    |
| 0.10 ‚Äì 0.39 | **Weak**                      |
| 0.40 ‚Äì 0.69 | **Moderate**                  |
| 0.70 ‚Äì 0.89 | **Strong**                    |
| 0.90 ‚Äì 1.00 | **Very strong / Excellent**   |


### Measures of the magnitude of an effect

- Standardised mean difference measures (d, g, Œî) ‚Äî quantify how far apart two groups are in SD units
- Correlation coefficients (r, œÅ) ‚Äî quantify the strength of association between two continuous variables
- Variance-accounted-for measures (R¬≤, Œ∑¬≤, œâ¬≤) ‚Äî quantify proportion of variance explained
- Association measures for categorical data (odds ratio, œÜ, Cram√©r's V, Cohen's w) ‚Äî quantify relationships in contingency tables

| Effect Size | Type | Range | Small | Medium | Large | Notes |
|-------------|------|-------|-------|--------|-------|-------|
| Cohen's d | Mean difference | -‚àû to +‚àû | 0.2 | 0.5 | 0.8 | t-tests, group comparisons |
| Hedges' g | Mean difference | -‚àû to +‚àû | 0.2 | 0.5 | 0.8 | Bias-corrected d; preferred in meta-analysis |
| Glass's Œî | Mean difference | -‚àû to +‚àû | 0.2 | 0.5 | 0.8 | Uses only control group SD; useful when variances unequal |
| Pearson's r | Correlation | -1 to +1 | 0.1 | 0.3 | 0.5 | Continuous variables |
| Spearman's œÅ | Correlation | -1 to +1 | 0.1 | 0.3 | 0.5 | Rank-order; non-parametric |
| R¬≤ | Variance explained | 0 to 1 | 0.01 | 0.09 | 0.25 | Squared correlation; regression |
| Œ∑¬≤ (eta-squared) | Variance explained | 0 to 1 | 0.01 | 0.06 | 0.14 | ANOVA; tends to overestimate |
| Partial Œ∑¬≤ | Variance explained | 0 to 1 | 0.01 | 0.06 | 0.14 | ANOVA; controls for other factors |
| œâ¬≤ (omega-squared) | Variance explained | 0 to 1 | 0.01 | 0.06 | 0.14 | Less biased than Œ∑¬≤ |
| Cohen's f | ANOVA effect | 0 to +‚àû | 0.1 | 0.25 | 0.4 | Related to Œ∑¬≤; used in power analysis |
| Odds ratio | Association | 0 to +‚àû | 1.5 | 2.5 | 4.0 | Categorical outcomes; 1 = no effect |
| Cohen's w | Chi-square | 0 to +‚àû | 0.1 | 0.3 | 0.5 | Categorical data |
| œÜ (phi) | Association | -1 to +1 | 0.1 | 0.3 | 0.5 | 2√ó2 contingency tables |
| Cram√©r's V | Association | 0 to 1 | 0.1 | 0.3 | 0.5 | Larger contingency tables |

The benchmarks come from Cohen (1988).