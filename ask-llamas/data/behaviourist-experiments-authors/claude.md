# Key Behaviorist Experiments and Theorists

## Ten Landmark Behaviorist Experiments

1. **Pavlov's Classical Conditioning (1901-1927)**  
   Ivan Pavlov demonstrated how neutral stimuli could elicit conditioned responses through association with unconditioned stimuli. His experiments with dogs showed how a previously neutral stimulus (bell) could trigger salivation after repeated pairing with food (Pavlov, 1927/1960).

2. **Watson's "Little Albert" Experiment (1920)**  
   John B. Watson and Rosalie Raynor conditioned fear in an infant ("Little Albert") by pairing a white rat with a loud noise, demonstrating how emotional responses could be conditioned (Watson & Raynor, 1920).

3. **Skinner's Operant Conditioning Chamber (1930s)**  
   B.F. Skinner's invention of the "Skinner Box" allowed precise measurement of how consequences shaped behavior through reinforcement schedules, establishing the principles of operant conditioning (Skinner, 1938).

4. **Thorndike's Puzzle Box Experiments (1898)**  
   Edward Thorndike's work with cats escaping from puzzle boxes led to his formulation of the Law of Effect, demonstrating that responses followed by satisfaction are strengthened (Thorndike, 1911).

5. **Bandura's Bobo Doll Experiment (1961)**  
   Albert Bandura showed that children learned aggressive behaviors by observing adults, establishing social learning theory as an extension of behaviorism (Bandura, Ross, & Ross, 1961).

6. **Garcia & Koelling's Taste Aversion Studies (1966)**  
   These experiments demonstrated biological constraints on learning by showing that rats could associate taste with nausea even with long delays between stimulus and response, challenging behaviorist assumptions about temporal contiguity (Garcia & Koelling, 1966).

7. **Seligman's Learned Helplessness Experiments (1967)**  
   Martin Seligman's work with dogs exposed to inescapable shock demonstrated how organisms learn to become passive when they perceive no control over adverse events (Seligman & Maier, 1967).

8. **Premack's Principle Experiments (1962)**  
   David Premack demonstrated that high-probability behaviors could reinforce low-probability behaviors, establishing what became known as the Premack Principle (Premack, 1962).

9. **Olds & Milner's Brain Stimulation Studies (1954)**  
   These researchers discovered that rats would repeatedly press a lever that stimulated certain brain regions, identifying neural pathways involved in reinforcement (Olds & Milner, 1954).

10. **Azrin's Token Economy Studies (1960s)**  
    Nathan Azrin and colleagues demonstrated how token economies could modify behavior in institutional settings, applying operant principles to clinical settings (Ayllon & Azrin, 1968).

## Five Key Behaviorist Theorists

1. **B.F. Skinner (1904-1990)**  
   Developed operant conditioning and the experimental analysis of behavior. His works include "The Behavior of Organisms" (1938) and "Science and Human Behavior" (1953).

2. **Ivan Pavlov (1849-1936)**  
   Pioneered work on classical conditioning. His research is compiled in "Conditioned Reflexes" (1927/1960).

3. **John B. Watson (1878-1958)**  
   Founded methodological behaviorism and advocated for objective study of behavior. Key work: "Behaviorism" (1924).

4. **Albert Bandura (1925-2021)**  
   Developed social learning theory, bridging behaviorism and cognitive approaches. Notable work: "Social Learning Theory" (1977).

5. **Edward Thorndike (1874-1949)**  
   Formulated the Law of Effect, a precursor to operant conditioning. Key publication: "Animal Intelligence" (1911).

## Behaviorist Research Since the 1990s

Contemporary behaviorist research has expanded into applied fields while incorporating findings from cognitive science and neuroscience:

1. **Relational Frame Theory (RFT)**  
   Developed by Hayes, Barnes-Holmes, and Roche (2001), RFT extends Skinnerian behaviorism to explain language and cognition as learned behavioral processes involving derived relational responding.

2. **Neurobehavioral Approaches**  
   Research by Donahoe and Palmer (2004) integrated neuroscience with behavioral principles, examining the neural substrates of operant and respondent conditioning.

3. **Computational Modeling of Behavior**  
   Behaviorists like Rescorla and Wagner continued refining mathematical models of conditioning. Glimcher's (2011) work in neuroeconomics applied behavioral principles to economic decision-making.

4. **Clinical Behavioral Interventions**  
   Applied Behavior Analysis (ABA) has been empirically validated for autism spectrum disorders (Lovaas, 1987; Sallows & Graupner, 2005). Cooper, Heron, and Heward (2007) documented these advances in their comprehensive text.

5. **Behavioral Economics**  
   Researchers like Kahneman and Tversky (1979) and later Thaler and Sunstein (2008) applied behavioral principles to economic decision-making, showing how reinforcement schedules affect consumer choices.

## Types of Reinforcement and Schedules

### Reinforcement Types

1. **Positive Reinforcement**  
   Adding a desirable stimulus to increase behavior frequency (Skinner, 1953). Example: Praise for task completion.

2. **Negative Reinforcement**  
   Removing an aversive stimulus to increase behavior frequency (Skinner, 1953). Example: Taking pain medication to remove discomfort.

3. **Positive Punishment**  
   Adding an aversive stimulus to decrease behavior (Azrin & Holz, 1966). Example: Receiving a traffic ticket.

4. **Negative Punishment**  
   Removing a desirable stimulus to decrease behavior (Lerman & Vorndran, 2002). Example: Removing television privileges.

### Reinforcement Schedules

1. **Continuous Reinforcement (CRF)**  
   Every instance of the behavior is reinforced. Research shows this produces rapid acquisition but quick extinction when reinforcement stops (Ferster & Skinner, 1957).

2. **Intermittent Reinforcement**  
   Only some instances of behavior are reinforced, creating greater resistance to extinction (Skinner, 1938).

Types of intermittent schedules include:

- **Fixed Ratio (FR)**: Reinforcement after a set number of responses
- **Variable Ratio (VR)**: Reinforcement after an unpredictable number of responses
- **Fixed Interval (FI)**: First response after a set time period is reinforced
- **Variable Interval (VI)**: First response after varying time periods is reinforced

Recent research by Lattal and Neef (2004) demonstrated that variable schedules create more persistent behavior than fixed schedules, explaining why gambling behavior persists despite intermittent payoffs.

## References

Ayllon, T., & Azrin, N. H. (1968). The token economy: A motivational system for therapy and rehabilitation. Appleton-Century-Crofts.

Azrin, N. H., & Holz, W. C. (1966). Punishment. In W. K. Honig (Ed.), Operant behavior: Areas of research and application (pp. 380-447). Appleton-Century-Crofts.

Bandura, A., Ross, D., & Ross, S. A. (1961). Transmission of aggression through imitation of aggressive models. The Journal of Abnormal and Social Psychology, 63(3), 575-582.

Cooper, J. O., Heron, T. E., & Heward, W. L. (2007). Applied behavior analysis (2nd ed.). Pearson.

Donahoe, J. W., & Palmer, D. C. (2004). Learning and complex behavior. Allyn & Bacon.

Ferster, C. B., & Skinner, B. F. (1957). Schedules of reinforcement. Appleton-Century-Crofts.

Garcia, J., & Koelling, R. A. (1966). Relation of cue to consequence in avoidance learning. Psychonomic Science, 4(1), 123-124.

Glimcher, P. W. (2011). Foundations of neuroeconomic analysis. Oxford University Press.

Hayes, S. C., Barnes-Holmes, D., & Roche, B. (Eds.). (2001). Relational frame theory: A post-Skinnerian account of human language and cognition. Kluwer Academic/Plenum Publishers.

Kahneman, D., & Tversky, A. (1979). Prospect theory: An analysis of decision under risk. Econometrica, 47(2), 263-292.

Lattal, K. A., & Neef, N. A. (2004). Recent reinforcement-schedule research and applied behavior analysis. Journal of Applied Behavior Analysis, 37(3), 383-386.

Lerman, D. C., & Vorndran, C. M. (2002). On the status of knowledge for using punishment: Implications for treating behavior disorders. Journal of Applied Behavior Analysis, 35(4), 431-464.

Lovaas, O. I. (1987). Behavioral treatment and normal educational and intellectual functioning in young autistic children. Journal of Consulting and Clinical Psychology, 55(1), 3-9.

Olds, J., & Milner, P. (1954). Positive reinforcement produced by electrical stimulation of septal area and other regions of rat brain. Journal of Comparative and Physiological Psychology, 47(6), 419-427.

Pavlov, I. P. (1960). Conditioned reflexes: An investigation of the physiological activity of the cerebral cortex (G. V. Anrep, Trans.). Dover Publications. (Original work published 1927)

Premack, D. (1962). Reversibility of the reinforcement relation. Science, 136(3512), 255-257.

Sallows, G. O., & Graupner, T. D. (2005). Intensive behavioral treatment for children with autism: Four-year outcome and predictors. American Journal on Mental Retardation, 110(6), 417-438.

Seligman, M. E., & Maier, S. F. (1967). Failure to escape traumatic shock. Journal of Experimental Psychology, 74(1), 1-9.

Skinner, B. F. (1938). The behavior of organisms: An experimental analysis. Appleton-Century-Crofts.

Skinner, B. F. (1953). Science and human behavior. Macmillan.

Thaler, R. H., & Sunstein, C. R. (2008). Nudge: Improving decisions about health, wealth, and happiness. Yale University Press.

Thorndike, E. L. (1911). Animal intelligence: Experimental studies. Macmillan.

Watson, J. B., & Raynor, R. (1920). Conditioned emotional reactions. Journal of Experimental Psychology, 3(1), 1-14.